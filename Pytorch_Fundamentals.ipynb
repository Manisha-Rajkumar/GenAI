{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manisha-Rajkumar/GenAI/blob/Week1/Pytorch_Fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvbSilYYA4DA"
      },
      "source": [
        "# **PyTorch Fundamentals: A Comprehensive Introduction to Tensor Operations and Deep Learning Foundations**\n",
        "\n",
        "**Course:** [Course Name/Code]  \n",
        "**Institution:** IIT Madras  \n",
        "**Author:** Prof. Ganapathy Krishnamurthi  \n",
        "**Date:** [Date]  \n",
        "\n",
        "---\n",
        "\n",
        "## **Learning Objectives**\n",
        "\n",
        "By the end of this tutorial, students will be able to:\n",
        "\n",
        "1. **Understand** the fundamental concepts of tensors and their role in deep learning\n",
        "2. **Create** and manipulate tensors using PyTorch's tensor operations\n",
        "3. **Apply** tensor operations for mathematical computations in deep learning contexts\n",
        "4. **Implement** tensor reshaping, indexing, and aggregation operations\n",
        "5. **Utilize** GPU acceleration for tensor computations\n",
        "6. **Debug** common tensor-related errors in PyTorch applications\n",
        "\n",
        "---\n",
        "\n",
        "## **Prerequisites**\n",
        "\n",
        "- Basic understanding of Python programming\n",
        "- Familiarity with NumPy arrays (recommended)\n",
        "- Linear algebra fundamentals (vectors, matrices, matrix multiplication)\n",
        "- Basic machine learning concepts (recommended but not required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dllgsUm8mD6j"
      },
      "source": [
        "## **1. Overview and Theoretical Background**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSNK7duj5SeU"
      },
      "source": [
        "### **1.1 Introduction to PyTorch**\n",
        "\n",
        "[PyTorch](https://pytorch.org/) is an open-source machine learning framework developed by Facebook's AI Research lab (FAIR). It provides a Python-based scientific computing package that serves as:\n",
        "\n",
        "1. **A replacement for NumPy** with the power of Graphics Processing Units (GPUs)\n",
        "2. **A deep learning research platform** that provides maximum flexibility and speed\n",
        "\n",
        "### **1.2 Applications and Use Cases**\n",
        "\n",
        "PyTorch enables researchers and practitioners to:\n",
        "\n",
        "- **Data Manipulation**: Process and transform multidimensional data structures efficiently\n",
        "- **Algorithm Development**: Implement machine learning and deep learning algorithms using automatic differentiation\n",
        "- **Model Prototyping**: Rapidly develop and test neural network architectures\n",
        "- **Production Deployment**: Scale models from research to production environments\n",
        "\n",
        "### **1.3 Industry Adoption**\n",
        "\n",
        "PyTorch has gained significant adoption across various sectors:\n",
        "\n",
        "- **Technology Companies**: Meta (Facebook), Tesla, Microsoft, and others utilize PyTorch for production systems\n",
        "- **Research Institutions**: [OpenAI](https://openai.com/blog/openai-pytorch/) and academic institutions leverage PyTorch for cutting-edge research\n",
        "- **Academic Community**: As of 2022, PyTorch is the [most utilized deep learning framework](https://paperswithcode.com/trends) in academic publications according to Papers With Code\n",
        "\n",
        "### **1.4 Advantages of PyTorch**\n",
        "\n",
        "**Research-Friendly Design**:\n",
        "- Dynamic computational graphs allow for flexible model architectures\n",
        "- Pythonic interface that integrates seamlessly with the Python ecosystem\n",
        "- Extensive debugging capabilities with standard Python debugging tools\n",
        "\n",
        "**Performance Optimization**:\n",
        "- Efficient GPU utilization through CUDA integration\n",
        "- Optimized tensor operations for numerical computations\n",
        "- Support for distributed training across multiple devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06mxMwCiBSFO"
      },
      "source": [
        "### **1.5 Theoretical Foundation: Understanding Tensors**\n",
        "\n",
        "**Tensors** represent the fundamental data structure in machine learning and deep learning applications. They serve as generalized mathematical objects that can represent:\n",
        "\n",
        "- **Scalars** (0-dimensional tensors): Single numerical values\n",
        "- **Vectors** (1-dimensional tensors): Arrays of numbers with directional properties\n",
        "- **Matrices** (2-dimensional tensors): Rectangular arrays for linear transformations\n",
        "- **Higher-order tensors** (n-dimensional): Multi-dimensional data structures for complex data\n",
        "\n",
        "### **1.6 Curriculum Structure**\n",
        "\n",
        "This tutorial systematically covers the essential tensor operations required for deep learning applications:\n",
        "\n",
        "| **Module** | **Learning Outcomes** | **Practical Applications** |\n",
        "|------------|----------------------|---------------------------|\n",
        "| **2. Tensor Introduction** | Understand tensor mathematics and data representation | Foundation for all ML/DL operations |\n",
        "| **3. Tensor Creation** | Master various tensor initialization methods | Data preprocessing and model initialization |\n",
        "| **4. Tensor Introspection** | Extract metadata and properties from tensors | Debugging and model analysis |\n",
        "| **5. Tensor Operations** | Perform mathematical operations on tensors | Forward and backward propagation in neural networks |\n",
        "| **6. Shape Manipulation** | Reshape and reorganize tensor dimensions | Data preprocessing and model compatibility |\n",
        "| **7. Tensor Indexing** | Access and modify specific tensor elements | Data sampling and feature extraction |\n",
        "| **8. NumPy Integration** | Convert between PyTorch tensors and NumPy arrays | Interoperability with existing data science workflows |\n",
        "| **9. Reproducibility** | Control randomness for consistent results | Ensuring reproducible research and debugging |\n",
        "| **10. GPU Acceleration** | Leverage GPU computing for faster operations | Scaling computations for large datasets and models |\n",
        "\n",
        "### **1.7 Mathematical Notation**\n",
        "\n",
        "Throughout this tutorial, we will use the following mathematical conventions:\n",
        "\n",
        "- **Scalars**: Lowercase italic letters (e.g., *x*, *y*, *Œ±*)\n",
        "- **Vectors**: Lowercase bold letters (e.g., **x**, **v**)\n",
        "- **Matrices**: Uppercase bold letters (e.g., **X**, **W**)\n",
        "- **Tensors**: Uppercase bold letters with tensor rank notation (e.g., **ùí≥** ‚àà ‚Ñù·µà¬πÀ£·µà¬≤À£...À£·µà‚Åø)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkOPL_CVmD6l"
      },
      "source": [
        "## **2. Environment Setup and Library Imports**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v3iRCRUTGeu"
      },
      "source": [
        "### **2.1 Installation Requirements**\n",
        "\n",
        "**Local Installation Prerequisites:**\n",
        "Before executing code in this tutorial locally, ensure PyTorch is properly installed following the [official PyTorch installation guide](https://pytorch.org/get-started/locally/). The installation process varies based on your operating system, Python version, and desired CUDA support.\n",
        "\n",
        "**Cloud Environment:**\n",
        "For **Google Colab** users, PyTorch and associated libraries are pre-installed and ready for use.\n",
        "\n",
        "### **2.2 Compatibility Notes**\n",
        "\n",
        "- **Python Version**: Python 3.7 or higher recommended\n",
        "- **CUDA Support**: Optional but recommended for GPU acceleration\n",
        "- **Memory Requirements**: Minimum 4GB RAM for basic operations\n",
        "- **Dependencies**: NumPy, Matplotlib (for visualization examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yhGBFUsAwjS"
      },
      "source": [
        "### **2.3 Library Import and Version Verification**\n",
        "\n",
        "We begin by importing the PyTorch library and verifying the installed version. This step ensures compatibility and helps with debugging potential version-specific issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VxEOik46Y4i",
        "outputId": "8195be8d-5c0b-4ce7-a8a8-408a0f6497d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 2.8.0+cu126\n"
          ]
        }
      ],
      "source": [
        "# Import the PyTorch library\n",
        "# PyTorch is the primary library for tensor operations and deep learning\n",
        "import torch\n",
        "\n",
        "# Display the PyTorch version\n",
        "# This is crucial for ensuring compatibility with code examples\n",
        "# Different PyTorch versions may have slight API differences\n",
        "print(f\"PyTorch Version: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check availability of GPU\n",
        "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(f\"CUDA version: {torch.version.cuda}\")\n",
        "  print(f\"Current CUDA Device: {torch.cuda.current_device()}\")\n",
        "  print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
        "  print(f\"Device properties: {torch.cuda.get_device_properties(0)}\")\n",
        "  print(f\"Total memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "  print(f\"Allocated memory: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
        "  print(f\"Free memory: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
        "  print(f\"Max memory: {torch.cuda.max_memory_reserved(0) / 1024**3:.2f} GB\")\n",
        "  print(f\"Max allocated memory: {torch.cuda.max_memory_allocated(0) / 1024**3:.2f} GB\")\n",
        "  print(f\"Max free memory: {torch.cuda.max_memory_reserved(0) / 1024**3:.2f} GB\")\n",
        "  print(f\"Max total memory: {torch.cuda.max_memory_reserved(0) / 1024**3:.2f} GB\")\n",
        "  print(f\"Device Capabilities: {torch.cuda.get_device_capability(0)}\")\n",
        "else:\n",
        "  print(\"CUDA is not available on this system.\")"
      ],
      "metadata": {
        "id": "7XyGwU1-U62a",
        "outputId": "7f06fd13-d610-497e-b553-07e66e0109c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is CUDA supported by this system? True\n",
            "CUDA version: 12.6\n",
            "Current CUDA Device: 0\n",
            "Device name: Tesla T4\n",
            "Device properties: _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15095MB, multi_processor_count=40, uuid=506eb3ff-56d7-6a49-3159-9f5fcf10ee0b, pci_bus_id=0, pci_device_id=4, pci_domain_id=0, L2_cache_size=4MB)\n",
            "Total memory: 14.74 GB\n",
            "Allocated memory: 0.00 GB\n",
            "Free memory: 0.00 GB\n",
            "Max memory: 0.00 GB\n",
            "Max allocated memory: 0.00 GB\n",
            "Max free memory: 0.00 GB\n",
            "Max total memory: 0.00 GB\n",
            "Device Capabilities: (7, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE6vghA0mD6m"
      },
      "source": [
        "## **3. Introduction to Tensors: Mathematical Foundations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-33BKR16iWc"
      },
      "source": [
        "### **3.1 Theoretical Background**\n",
        "\n",
        "**Tensors constitute the fundamental building blocks of machine learning computations.** In the context of deep learning, tensors serve as the primary data structure for representing:\n",
        "\n",
        "- **Input data**: Images, text sequences, audio signals, and tabular data\n",
        "- **Model parameters**: Weights and biases in neural networks\n",
        "- **Intermediate computations**: Activations and gradients during training\n",
        "- **Output predictions**: Classification probabilities and regression values\n",
        "\n",
        "### **3.2 Mathematical Definition**\n",
        "\n",
        "A tensor **T** of rank **n** (or order **n**) is a mathematical object with **n** indices, where each index can range over a specific dimension. Formally:\n",
        "\n",
        "**T** ‚àà ‚Ñù·µà¬πÀ£·µà¬≤À£...À£·µà‚Åø\n",
        "\n",
        "Where:\n",
        "- **d‚ÇÅ, d‚ÇÇ, ..., d‚Çô** represent the size of each dimension\n",
        "- **n** is the rank/order of the tensor\n",
        "- **‚Ñù** denotes the set of real numbers (though tensors can contain other data types)\n",
        "\n",
        "### **3.3 Computational Significance**\n",
        "\n",
        "Tensors enable efficient computation through:\n",
        "\n",
        "1. **Vectorization**: Operations on entire arrays rather than individual elements\n",
        "2. **Parallelization**: GPU acceleration for simultaneous computations\n",
        "3. **Automatic Differentiation**: Gradient computation for optimization algorithms\n",
        "4. **Memory Efficiency**: Optimized storage and access patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu_iPGdSAj_p"
      },
      "source": [
        "### **3.4 Data Representation Through Tensors**\n",
        "\n",
        "**Tensors provide a unified mathematical framework for representing diverse data types in numerical form.** This numerical representation is essential because machine learning algorithms operate exclusively on numerical data.\n",
        "\n",
        "#### **3.4.1 Image Representation Example**\n",
        "\n",
        "Consider a color image representation as a 3-dimensional tensor with shape `[channels, height, width]`:\n",
        "\n",
        "- **Channels (C)**: Color information (typically 3 for RGB: Red, Green, Blue)\n",
        "- **Height (H)**: Vertical resolution in pixels  \n",
        "- **Width (W)**: Horizontal resolution in pixels\n",
        "\n",
        "For example, a standard image might have shape `[3, 224, 224]`, representing:\n",
        "- **3 color channels** (RGB)\n",
        "- **224 pixels** in height\n",
        "- **224 pixels** in width\n",
        "- **Total elements**: 3 √ó 224 √ó 224 = 150,528 numerical values\n",
        "\n",
        "![Tensor representation of an image showing the breakdown into color channels and spatial dimensions](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)\n",
        "\n",
        "*Figure 3.1: Transformation of visual data into tensor representation for computational processing.*\n",
        "*Source: learnpytorch.io*\n",
        "\n",
        "#### **3.4.2 Data Type Implications**\n",
        "\n",
        "The choice of tensor dimensions and data organization significantly impacts:\n",
        "- **Memory consumption**: Higher dimensions require more storage\n",
        "- **Computational complexity**: More dimensions increase operation costs\n",
        "- **Model architecture design**: Network layers must match tensor shapes\n",
        "- **Training efficiency**: Optimal batch sizes depend on tensor dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8FnGS0rmD6n"
      },
      "source": [
        "## **4. Tensor Creation and Initialization Methods**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFF0N2TU7S7Q"
      },
      "source": [
        "### **4.1 Theoretical Framework**\n",
        "\n",
        "The [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) class serves as the fundamental data structure in PyTorch. Understanding tensor creation methods is crucial for:\n",
        "\n",
        "- **Data preprocessing**: Converting raw data into tensor format\n",
        "- **Model initialization**: Creating parameter tensors with appropriate shapes\n",
        "- **Experimentation**: Generating synthetic data for testing and validation\n",
        "\n",
        "### **4.2 Tensor Hierarchy and Classification**\n",
        "\n",
        "**4.2.1 Scalar Tensors (Rank 0)**\n",
        "\n",
        "A **scalar** represents a single numerical value and constitutes a **zero-dimensional tensor**. In mathematical notation:\n",
        "- **Mathematical representation**: *s* ‚àà ‚Ñù\n",
        "- **PyTorch shape**: `torch.Size([])`\n",
        "- **Dimensions**: 0\n",
        "\n",
        "**Properties:**\n",
        "- Contains exactly one element\n",
        "- No directional information\n",
        "- Often used for loss values, learning rates, and single metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUDgG2zk7Us5",
        "outputId": "38e20d7a-60b3-425f-c0ff-d0d63c20ca00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scalar tensor: 7\n",
            "Scalar value: 7\n",
            "Data type: torch.int64\n",
            "Shape: torch.Size([])\n",
            "Size: torch.Size([])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a scalar tensor (0-dimensional tensor)\n",
        "# Scalars contain a single numerical value and have no dimensions\n",
        "# They are fundamental building blocks for more complex tensor operations\n",
        "\n",
        "scalar = torch.tensor(7)  # Create a scalar tensor with value 7\n",
        "\n",
        "# Display the scalar tensor\n",
        "print(f\"Scalar tensor: {scalar}\")\n",
        "print(f\"Scalar value: {scalar.item()}\")  # Extract the Python number\n",
        "print(f\"Data type: {scalar.dtype}\")       # Check the data type\n",
        "print(f\"Shape: {scalar.shape}\")           # Shape is empty for scalars\n",
        "print(f\"Size: {scalar.size()}\")           # Alternative way to check shape\n",
        "\n",
        "# The scalar tensor object contains metadata beyond just the value:\n",
        "# - dtype: The data type (default is inferred from input)\n",
        "# - device: The computational device (CPU or GPU)\n",
        "# - requires_grad: Whether to track gradients for automatic differentiation\n",
        "\n",
        "scalar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqSuhW7rTGey"
      },
      "source": [
        "### **4.3 Tensor Dimensionality Analysis**\n",
        "\n",
        "**Tensor dimensionality** (or rank) indicates the number of indices required to specify an element within the tensor. The `ndim` attribute provides this crucial information for tensor manipulation and debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV98Yz868bav",
        "outputId": "a05ead94-eabc-4b2a-eee9-083b056f22e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of dimensions (rank): 0\n",
            "Verification: A scalar has 0 dimensions\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the number of dimensions (rank) of the scalar tensor\n",
        "# For a scalar, this should return 0 since it has no dimensions\n",
        "dimensionality = scalar.ndim\n",
        "\n",
        "print(f\"Number of dimensions (rank): {dimensionality}\")\n",
        "print(f\"Verification: A scalar has {dimensionality} dimensions\")\n",
        "\n",
        "# Understanding dimensionality is crucial for:\n",
        "# 1. Matrix operations (shapes must be compatible)\n",
        "# 2. Neural network layer design (input/output dimensions must match)\n",
        "# 3. Data preprocessing (ensuring correct tensor shapes)\n",
        "\n",
        "dimensionality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO2YW_QGTGez"
      },
      "source": [
        "### **4.4 Value Extraction from Tensors**\n",
        "\n",
        "To retrieve the underlying numerical value from a tensor, PyTorch provides the `item()` method. This method is essential for:\n",
        "\n",
        "- **Metric reporting**: Extracting loss values for logging\n",
        "- **Conditional operations**: Using tensor values in Python control structures  \n",
        "- **Debugging**: Inspecting individual tensor elements\n",
        "\n",
        "**Important constraint**: The `item()` method only works with tensors containing exactly one element (single-element tensors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k4cyKumPfbE",
        "outputId": "b4a987f3-d86c-44b5-f3d1-1ea776f03b5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor: 7\n",
            "Extracted Python value: 7\n",
            "Type of tensor: <class 'torch.Tensor'>\n",
            "Type of extracted value: <class 'int'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extract the Python numerical value from a single-element tensor\n",
        "# The item() method converts a PyTorch tensor to a Python scalar\n",
        "# This is essential when you need to use tensor values in standard Python operations\n",
        "\n",
        "python_value = scalar.item()\n",
        "\n",
        "print(f\"Original tensor: {scalar}\")\n",
        "print(f\"Extracted Python value: {python_value}\")\n",
        "print(f\"Type of tensor: {type(scalar)}\")\n",
        "print(f\"Type of extracted value: {type(python_value)}\")\n",
        "\n",
        "# Practical applications of item():\n",
        "# 1. Loss monitoring: loss_value = loss_tensor.item()\n",
        "# 2. Metric computation: accuracy = correct_predictions.item() / total_samples\n",
        "# 3. Conditional logic: if accuracy_tensor.item() > threshold: ...\n",
        "# 4. Logging: print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Note: Attempting item() on multi-element tensors will raise an error\n",
        "# For multi-element tensors, use indexing to access specific elements first\n",
        "\n",
        "python_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYs7ulrATGe0"
      },
      "source": [
        "### **4.5 Vector Tensors (Rank 1)**\n",
        "\n",
        "#### **4.5.1 Mathematical Definition**\n",
        "\n",
        "A **vector** represents a one-dimensional tensor containing multiple numerical values arranged in a specific order. In mathematical notation:\n",
        "- **Mathematical representation**: **v** ‚àà ‚Ñù‚Åø\n",
        "- **PyTorch shape**: `torch.Size([n])`  \n",
        "- **Dimensions**: 1\n",
        "\n",
        "#### **4.5.2 Properties and Characteristics**\n",
        "\n",
        "**Vectors possess several important properties:**\n",
        "- **Ordered sequence**: Elements have specific positions (indices)\n",
        "- **Directional information**: Can represent direction and magnitude\n",
        "- **Flexible representation**: Can encode various types of information\n",
        "\n",
        "**Real-world applications:**\n",
        "- **Housing features**: `[bedrooms, bathrooms, square_feet]`\n",
        "- **Word embeddings**: Dense representations of words in NLP\n",
        "- **Feature vectors**: Extracted features from raw data\n",
        "- **Probability distributions**: Categorical probability outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IZF6ASs8QH9",
        "outputId": "c1a52619-c18b-45a2-edb3-b80a2cc33a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector tensor: tensor([7., 7.])\n",
            "Data type: torch.float32\n",
            "Dimension: 1\n",
            "Shape: torch.Size([2])\n",
            "Number of elements: 2\n",
            "L2 norm (Euclidean length): 9.8995\n",
            "Sum of elements: 14.0\n",
            "Mean of elements: 7.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([7., 7.])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a vector tensor (1-dimensional tensor)\n",
        "# Vectors contain multiple values arranged in a single dimension\n",
        "# They are fundamental for representing sequences, features, and embeddings\n",
        "\n",
        "vector = torch.tensor([7.0, 7.0])  # Create a vector with two identical elements\n",
        "\n",
        "print(f\"Vector tensor: {vector}\")\n",
        "print(f\"Data type: {vector.dtype}\")\n",
        "print(f\"Dimension: {vector.dim()}\")\n",
        "print(f\"Shape: {vector.shape}\")\n",
        "print(f\"Number of elements: {vector.numel()}\")  # Total number of elements\n",
        "\n",
        "# Vector interpretation examples:\n",
        "# [7, 7] could represent:\n",
        "# - Coordinates in 2D space (x=7, y=7)\n",
        "# - Two identical measurements\n",
        "# - A repeated pattern or signal\n",
        "# - Feature values for two attributes\n",
        "\n",
        "# Mathematical properties:\n",
        "print(f\"L2 norm (Euclidean length): {torch.norm(vector).item():.4f}\")\n",
        "print(f\"Sum of elements: {torch.sum(vector).item()}\")\n",
        "print(f\"Mean of elements: {torch.mean(vector.float()).item():.4f}\")\n",
        "\n",
        "vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYY2w2tk_NVj"
      },
      "source": [
        "### **4.6 Matrix Tensors (Rank 2)**\n",
        "\n",
        "**Mathematical Definition:**\n",
        "A **matrix** represents a two-dimensional tensor organized in rows and columns. In mathematical notation:\n",
        "- **Mathematical representation**: **M** ‚àà ‚Ñù·µêÀ£‚Åø\n",
        "- **PyTorch shape**: `torch.Size([m, n])`\n",
        "- **Dimensions**: 2\n",
        "\n",
        "**Properties:**\n",
        "- **Rows (m)**: First dimension, representing horizontal sequences\n",
        "- **Columns (n)**: Second dimension, representing vertical sequences  \n",
        "- **Linear transformations**: Matrices can represent linear mappings between vector spaces\n",
        "- **Data organization**: Natural structure for tabular data and 2D relationships"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5iNwCYL8QO9",
        "outputId": "16449acc-c219-45ff-9978-7dce284195b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix tensor:\n",
            "tensor([[ 7.,  8.],\n",
            "        [ 9., 10.]])\n",
            "Data type: torch.float32\n",
            "Dimension: 2\n",
            "Shape: torch.Size([2, 2])\n",
            "Number of dimensions: 2\n",
            "Total elements: 4\n",
            "\n",
            "Matrix properties:\n",
            "Determinant: -2.0000\n",
            "Trace (sum of diagonal): 17.0\n",
            "Frobenius norm: 17.1464\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a matrix tensor (2-dimensional tensor)\n",
        "# Matrices are fundamental for linear algebra operations in machine learning\n",
        "# They represent linear transformations, weight matrices, and 2D data structures\n",
        "\n",
        "MATRIX = torch.tensor([[7.0, 8.0],      # First row: [7, 8]\n",
        "                       [9.0, 10.0]])    # Second row: [9, 10]\n",
        "\n",
        "print(f\"Matrix tensor:\\n{MATRIX}\")\n",
        "print(f\"Data type: {MATRIX.dtype}\")\n",
        "print(f\"Dimension: {MATRIX.dim()}\")  # Should return 2 for a matrix\n",
        "print(f\"Shape: {MATRIX.shape}\")  # Returns torch.Size([rows, columns])\n",
        "print(f\"Number of dimensions: {MATRIX.ndim}\")\n",
        "print(f\"Total elements: {MATRIX.numel()}\")\n",
        "\n",
        "# Matrix properties and operations:\n",
        "print(f\"\\nMatrix properties:\")\n",
        "print(f\"Determinant: {torch.det(MATRIX.float()).item():.4f}\")  # Requires float type\n",
        "print(f\"Trace (sum of diagonal): {torch.trace(MATRIX).item()}\")\n",
        "print(f\"Frobenius norm: {torch.norm(MATRIX).item():.4f}\")\n",
        "\n",
        "# Matrix interpretations:\n",
        "# - Weight matrix in neural networks (input_features √ó output_features)\n",
        "# - Transformation matrix for geometric operations\n",
        "# - Correlation matrix for feature relationships\n",
        "# - Adjacency matrix for graph representations\n",
        "\n",
        "MATRIX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvLpUvrKTGe4"
      },
      "source": [
        "### **4.7 Higher-Order Tensors (Rank ‚â• 3)**\n",
        "\n",
        "**Mathematical Definition:**\n",
        "Higher-order tensors extend beyond matrices to represent multi-dimensional data structures. For a rank-3 tensor:\n",
        "- **Mathematical representation**: **ùíØ** ‚àà ‚Ñù·µà¬πÀ£·µà¬≤À£·µà¬≥\n",
        "- **PyTorch shape**: `torch.Size([d1, d2, d3])`\n",
        "- **Dimensions**: 3 or higher\n",
        "\n",
        "**Applications in Deep Learning:**\n",
        "- **Batch processing**: `[batch_size, features]` or `[batch_size, channels, height, width]`\n",
        "- **Sequence modeling**: `[batch_size, sequence_length, feature_dimension]`\n",
        "- **Computer vision**: `[batch_size, channels, height, width]` for image batches\n",
        "- **Video processing**: `[batch_size, time_steps, channels, height, width]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEMDQr188QWW",
        "outputId": "2ea2d8d1-5a96-4059-e578-f2c1f1df19b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3D Tensor:\n",
            "tensor([[[1, 2, 3],\n",
            "         [3, 6, 9],\n",
            "         [2, 4, 5]]])\n",
            "Data type: torch.int64\n",
            "Dimension: 3\n",
            "Shape: torch.Size([1, 3, 3])\n",
            "Number of dimensions: 3\n",
            "Total elements: 9\n",
            "\n",
            "Dimensional analysis:\n",
            "Outer dimension (axis 0): 1 - Number of 3x3 matrices\n",
            "Middle dimension (axis 1): 3 - Number of rows per matrix\n",
            "Inner dimension (axis 2): 3 - Number of columns per row\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [2, 4, 5]]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a higher-order tensor (3-dimensional tensor)\n",
        "# This example creates a rank-3 tensor with shape [1, 3, 3]\n",
        "# The triple bracket notation [[[...]]] indicates three dimensions\n",
        "\n",
        "TENSOR = torch.tensor([[[1, 2, 3],     # First 3x3 matrix, row 1\n",
        "                        [3, 6, 9],     # First 3x3 matrix, row 2\n",
        "                        [2, 4, 5]]])   # First 3x3 matrix, row 3\n",
        "\n",
        "print(f\"3D Tensor:\\n{TENSOR}\")\n",
        "print(f\"Data type: {TENSOR.dtype}\")\n",
        "print(f\"Dimension: {TENSOR.dim()}\")  # Should return 3 for a 3D tensor\n",
        "print(f\"Shape: {TENSOR.shape}\")  # torch.Size([1, 3, 3])\n",
        "print(f\"Number of dimensions: {TENSOR.ndim}\")\n",
        "print(f\"Total elements: {TENSOR.numel()}\")\n",
        "\n",
        "# Shape interpretation: [1, 3, 3]\n",
        "# - Dimension 0: 1 \"slice\" or \"channel\" (outermost dimension)\n",
        "# - Dimension 1: 3 rows within each slice\n",
        "# - Dimension 2: 3 columns within each row\n",
        "\n",
        "print(f\"\\nDimensional analysis:\")\n",
        "print(f\"Outer dimension (axis 0): {TENSOR.shape[0]} - Number of 3x3 matrices\")\n",
        "print(f\"Middle dimension (axis 1): {TENSOR.shape[1]} - Number of rows per matrix\")\n",
        "print(f\"Inner dimension (axis 2): {TENSOR.shape[2]} - Number of columns per row\")\n",
        "\n",
        "# Real-world analogy: This could represent:\n",
        "# - A single grayscale image patch (1 channel, 3x3 pixels)\n",
        "# - One time step of a 3x3 feature map in a CNN\n",
        "# - A small kernel/filter in convolutional operations\n",
        "# - A single sample in a batch of 3x3 matrices\n",
        "\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxk8GU7oTGe5"
      },
      "source": [
        "Alright, it outputs `torch.Size([1, 3, 3])`.\n",
        "\n",
        "The dimensions go outer to inner.\n",
        "\n",
        "That means there's 1 dimension of 3 by 3.\n",
        "\n",
        "![example of different tensor dimensions](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)\n",
        "Source: learnpytorch.io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmJKkXD7TGe4"
      },
      "source": [
        "The one we just created could be the sales numbers for a steak and almond butter store.\n",
        "\n",
        "![a simple tensor in google sheets showing day of week, steak sales and almond butter sales](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_simple_tensor.png)\n",
        "\n",
        "Source: learnpytorch.io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO4lSoHjmD6q"
      },
      "source": [
        "**Note:** You might've noticed the usage of lowercase letters for `scalar` and `vector` and uppercase letters for `MATRIX` and `TENSOR`. This was on purpose. In practice, you'll often see scalars and vectors denoted as lowercase letters such as `y` or `a`. And matrices and tensors denoted as uppercase letters such as `X` or `W`.\n",
        "\n",
        "You also might notice the names matrix and tensor used interchangeably. This is common. Since in PyTorch you're often dealing with `torch.Tensor`s (hence the tensor name), however, the shape and dimensions of what's inside will dictate what it actually is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYcusyUO_xYZ"
      },
      "source": [
        "### **Summary**\n",
        "\n",
        "| Name | What is it? | Number of dimensions | Lower or upper (usually/example) |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| **scalar** | a single number | 0 | Lower (`a`) |\n",
        "| **vector** | a number with direction (e.g. wind speed with direction) but can also have many other numbers | 1 | Lower (`y`) |\n",
        "| **matrix** | a 2-dimensional array of numbers | 2 | Upper (`Q`) |\n",
        "| **tensor** | an n-dimensional array of numbers | can be any number, a 0-dimension tensor is a scalar, a 1-dimension tensor is a vector | Upper (`X`) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gS7ACevmD6q"
      },
      "source": [
        "## **5. Specialized Tensor Initialization Methods**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MQNTY0eTGe6"
      },
      "source": [
        "### **5.1 Zero and One Initialization**\n",
        "\n",
        "**Theoretical Background:**\n",
        "Zero and one tensors serve crucial roles in deep learning applications:\n",
        "\n",
        "#### **5.1.1 Zero Tensors**\n",
        "- **Mathematical representation**: **0** ‚àà ‚Ñù·µà¬πÀ£·µà¬≤À£...À£·µà‚Åø where all elements equal 0\n",
        "- **Applications**:\n",
        "  - **Bias initialization**: Starting with zero bias in neural networks\n",
        "  - **Padding operations**: Adding zero-valued boundaries to tensors\n",
        "  - **Masking**: Creating attention masks or sequence padding\n",
        "  - **Memory allocation**: Pre-allocating tensors before filling with computed values\n",
        "\n",
        "#### **5.1.2 One Tensors**  \n",
        "- **Mathematical representation**: **1** ‚àà ‚Ñù·µà¬πÀ£·µà¬≤À£...À£·µà‚Åø where all elements equal 1\n",
        "- **Applications**:\n",
        "  - **Identity operations**: Creating identity matrices for linear algebra\n",
        "  - **Normalization**: Serving as multiplicative identity elements\n",
        "  - **Template creation**: Base tensors for subsequent operations\n",
        "  - **Testing**: Simplified computations for debugging and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCzhd0hl9Vp6",
        "outputId": "1994673c-fa19-4037-9bd0-22f353594d9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zero tensor:\n",
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "Shape: torch.Size([3, 4])\n",
            "Data type: torch.float32\n",
            "Device: cpu\n",
            "Total elements: 12\n",
            "\n",
            "Tensor properties:\n",
            "Memory usage (bytes): 48\n",
            "Is contiguous in memory: True\n",
            "Requires gradient: False\n",
            "\n",
            "Mathematical properties:\n",
            "Sum of all elements: 0.0\n",
            "Mean of all elements: 0.0\n",
            "Standard deviation: 0.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]),\n",
              " torch.float32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor filled with zeros using torch.zeros()\n",
        "# The size parameter determines the tensor dimensions\n",
        "# This is essential for initializing tensors before computation\n",
        "\n",
        "zeros = torch.zeros(size=(3, 4))  # Create a 3x4 matrix of zeros\n",
        "\n",
        "print(f\"Zero tensor:\\n{zeros}\")\n",
        "print(f\"Shape: {zeros.shape}\")\n",
        "print(f\"Data type: {zeros.dtype}\")  # Default is torch.float32\n",
        "print(f\"Device: {zeros.device}\")    # Default is CPU\n",
        "print(f\"Total elements: {zeros.numel()}\")\n",
        "\n",
        "# Memory and computational considerations:\n",
        "print(f\"\\nTensor properties:\")\n",
        "print(f\"Memory usage (bytes): {zeros.element_size() * zeros.numel()}\")\n",
        "print(f\"Is contiguous in memory: {zeros.is_contiguous()}\")\n",
        "print(f\"Requires gradient: {zeros.requires_grad}\")\n",
        "\n",
        "# Common use cases for zero tensors:\n",
        "# 1. Neural network bias initialization: bias = torch.zeros(output_features)\n",
        "# 2. Attention masks: mask = torch.zeros(seq_len, seq_len)\n",
        "# 3. Gradient accumulation: grad_accumulator = torch.zeros_like(parameter)\n",
        "# 4. Batch processing placeholders: batch_data = torch.zeros(batch_size, features)\n",
        "\n",
        "# Mathematical verification:\n",
        "print(f\"\\nMathematical properties:\")\n",
        "print(f\"Sum of all elements: {torch.sum(zeros).item()}\")\n",
        "print(f\"Mean of all elements: {torch.mean(zeros).item()}\")\n",
        "print(f\"Standard deviation: {torch.std(zeros).item()}\")\n",
        "\n",
        "zeros, zeros.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRe6sSXiTGe6",
        "outputId": "d804406a-faad-48f4-abed-6c32701bd0dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ones tensor:\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "Shape: torch.Size([3, 4])\n",
            "Data type: torch.float32\n",
            "Device: cpu\n",
            "\n",
            "Mathematical analysis:\n",
            "Sum of all elements: 12.0\n",
            "Product of all elements: 1.0\n",
            "Mean of all elements: 1.0\n",
            "L2 norm: 3.4641\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]),\n",
              " torch.float32)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor filled with ones using torch.ones()\n",
        "# Similar to zeros, but all elements are initialized to 1.0\n",
        "# Useful for multiplicative identity operations and normalization\n",
        "\n",
        "ones = torch.ones(size=(3, 4))  # Create a 3x4 matrix of ones\n",
        "\n",
        "print(f\"Ones tensor:\\n{ones}\")\n",
        "print(f\"Shape: {ones.shape}\")\n",
        "print(f\"Data type: {ones.dtype}\")  # Default is torch.float32\n",
        "print(f\"Device: {ones.device}\")\n",
        "\n",
        "# Mathematical properties of ones tensor:\n",
        "print(f\"\\nMathematical analysis:\")\n",
        "print(f\"Sum of all elements: {torch.sum(ones).item()}\")  # Should equal total elements\n",
        "print(f\"Product of all elements: {torch.prod(ones).item()}\")  # Should equal 1.0\n",
        "print(f\"Mean of all elements: {torch.mean(ones).item()}\")  # Should equal 1.0\n",
        "print(f\"L2 norm: {torch.norm(ones).item():.4f}\")  # Square root of number of elements\n",
        "\n",
        "# Practical applications:\n",
        "# 1. Identity matrix creation: I = torch.eye(n) or torch.ones(n,n) with modifications\n",
        "# 2. Masking operations: valid_mask = torch.ones(sequence_length)\n",
        "# 3. Weight initialization scaling: weights = torch.ones(shape) * init_scale\n",
        "# 4. Attention mechanisms: attention_weights = torch.ones(num_heads, seq_len, seq_len)\n",
        "\n",
        "# Computational efficiency note:\n",
        "# Both zeros() and ones() are optimized operations that don't require\n",
        "# element-by-element assignment, making them very fast for large tensors\n",
        "\n",
        "ones, ones.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dms7G4nkTGe5"
      },
      "source": [
        "### **5.2 Random Tensor Generation**\n",
        "\n",
        "**Theoretical Foundation:**\n",
        "Random tensors are fundamental in machine learning for:\n",
        "\n",
        "1. **Parameter Initialization**: Breaking symmetry in neural networks\n",
        "2. **Stochastic Processes**: Modeling uncertainty and variability  \n",
        "3. **Data Augmentation**: Creating synthetic training examples\n",
        "4. **Monte Carlo Methods**: Approximating complex probability distributions\n",
        "\n",
        "#### **5.2.1 Uniform Random Distribution**\n",
        "\n",
        "The [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) function generates tensors with values sampled from a uniform distribution over the interval [0, 1):\n",
        "\n",
        "**Mathematical representation**: X ~ U(0,1)\n",
        "- **Probability density function**: f(x) = 1 for x ‚àà [0,1), 0 otherwise\n",
        "- **Mean**: Œº = 0.5\n",
        "- **Variance**: œÉ¬≤ = 1/12 ‚âà 0.083"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOJEtDx--GnK",
        "outputId": "9ff3b4db-46f2-4d4d-f5ac-eb0cb0abed43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random tensor:\n",
            "tensor([[0.5607, 0.0444, 0.4183, 0.7015],\n",
            "        [0.4447, 0.5234, 0.1832, 0.2898],\n",
            "        [0.5075, 0.8066, 0.1623, 0.8025]])\n",
            "Shape: torch.Size([3, 4])\n",
            "Data type: torch.float32\n",
            "\n",
            "Statistical properties:\n",
            "Minimum value: 0.044396\n",
            "Maximum value: 0.806584\n",
            "Mean value: 0.453747\n",
            "Standard deviation: 0.248735\n",
            "Theoretical std for U(0,1): 0.288675\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[0.5607, 0.0444, 0.4183, 0.7015],\n",
              "         [0.4447, 0.5234, 0.1832, 0.2898],\n",
              "         [0.5075, 0.8066, 0.1623, 0.8025]]),\n",
              " torch.float32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor with random values from uniform distribution [0, 1)\n",
        "# Random tensors are crucial for neural network weight initialization\n",
        "# They help break symmetry and enable effective learning\n",
        "\n",
        "random_tensor = torch.rand(size=(3, 4))  # 3x4 matrix with random values\n",
        "\n",
        "print(f\"Random tensor:\\n{random_tensor}\")\n",
        "print(f\"Shape: {random_tensor.shape}\")\n",
        "print(f\"Data type: {random_tensor.dtype}\")\n",
        "\n",
        "# Statistical analysis of the random tensor:\n",
        "print(f\"\\nStatistical properties:\")\n",
        "print(f\"Minimum value: {torch.min(random_tensor).item():.6f}\")\n",
        "print(f\"Maximum value: {torch.max(random_tensor).item():.6f}\")\n",
        "print(f\"Mean value: {torch.mean(random_tensor).item():.6f}\")  # Should be ~0.5\n",
        "print(f\"Standard deviation: {torch.std(random_tensor).item():.6f}\")  # Should be ~0.289\n",
        "\n",
        "# Theoretical vs. empirical comparison:\n",
        "# For uniform distribution U(0,1): theoretical_mean = 0.5, theoretical_std = 1/‚àö12 ‚âà 0.289\n",
        "theoretical_std = 1.0 / (12**0.5)\n",
        "print(f\"Theoretical std for U(0,1): {theoretical_std:.6f}\")\n",
        "\n",
        "# Applications in deep learning:\n",
        "# 1. Weight initialization: weights = torch.rand(input_size, output_size) * scale\n",
        "# 2. Dropout simulation: dropout_mask = (torch.rand(size) > dropout_rate).float()\n",
        "# 3. Data augmentation: noise = torch.rand(data.shape) * noise_level\n",
        "# 4. Monte Carlo sampling: samples = torch.rand(num_samples, dimensions)\n",
        "\n",
        "# Note: Each execution will produce different values due to randomness\n",
        "# This is essential for stochastic training processes in machine learning\n",
        "\n",
        "random_tensor, random_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMF_NUp3Ym__",
        "outputId": "b71d92d8-214a-4206-e52a-c1c05d17265d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image tensor shape: torch.Size([224, 224, 3])\n",
            "Number of dimensions: 3\n",
            "Total elements: 150,528\n",
            "\n",
            "Memory analysis:\n",
            "Bytes per element: 4\n",
            "Total memory usage: 602,112 bytes (0.57 MB)\n",
            "\n",
            "Image properties:\n",
            "Height: 224 pixels\n",
            "Width: 224 pixels\n",
            "Channels: 3 (RGB color channels)\n",
            "Total pixels: 50,176\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random tensor with image-like dimensions\n",
        "# Common computer vision tensor shape: (height, width, channels)\n",
        "# This simulates a standard 224x224 RGB image used in many CV models\n",
        "\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "print(f\"Image tensor shape: {random_image_size_tensor.shape}\")\n",
        "print(f\"Number of dimensions: {random_image_size_tensor.ndim}\")\n",
        "print(f\"Total elements: {random_image_size_tensor.numel():,}\")  # Format with commas\n",
        "\n",
        "# Memory analysis for large tensors:\n",
        "element_size = random_image_size_tensor.element_size()  # Bytes per element\n",
        "total_memory = random_image_size_tensor.numel() * element_size\n",
        "print(f\"\\nMemory analysis:\")\n",
        "print(f\"Bytes per element: {element_size}\")\n",
        "print(f\"Total memory usage: {total_memory:,} bytes ({total_memory/1024/1024:.2f} MB)\")\n",
        "\n",
        "# Dimension interpretation for computer vision:\n",
        "height, width, channels = random_image_size_tensor.shape\n",
        "print(f\"\\nImage properties:\")\n",
        "print(f\"Height: {height} pixels\")\n",
        "print(f\"Width: {width} pixels\")\n",
        "print(f\"Channels: {channels} (RGB color channels)\")\n",
        "print(f\"Total pixels: {height * width:,}\")\n",
        "\n",
        "# Standard image formats in deep learning:\n",
        "# - ImageNet standard: 224x224x3 (this example)\n",
        "# - CIFAR-10: 32x32x3\n",
        "# - MNIST: 28x28x1 (grayscale)\n",
        "# - High-resolution: 512x512x3 or larger\n",
        "\n",
        "# Note: In practice, we often use (C, H, W) format for PyTorch models\n",
        "# This tensor uses (H, W, C) format, which is common for data loading\n",
        "\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hib1NYrSarL2"
      },
      "source": [
        "### **5.3 Creating a range and tensors like**\n",
        "\n",
        "Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100.\n",
        "\n",
        "`torch.arange(start, end, step)`\n",
        "\n",
        "Where:\n",
        "* `start` = start of range (e.g. 0)\n",
        "* `end` = end of range (e.g. 10)\n",
        "* `step` = how many steps in between each value (e.g. 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IqUs81d9W4W",
        "outputId": "1e1c2f81-0e82-4366-fffb-4bee007b869f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a range of values 0 to 10\n",
        "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
        "zero_to_ten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-bXf0Ugbh-D"
      },
      "source": [
        "Sometimes you might want one tensor of a certain type with the same shape as another tensor.\n",
        "\n",
        "For example, a tensor of all zeros with the same shape as a previous tensor.\n",
        "\n",
        "To do so you can use [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) which return a tensor filled with zeros or ones in the same shape as the `input` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvXwUut5BhHq",
        "outputId": "cc179d46-6a56-406f-ebd3-d26f8b6a4ecd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Can also create a tensor of zeros similar to another tensor\n",
        "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huKZ6QlYTGe7"
      },
      "source": [
        "### **5.4 Tensor datatypes**\n",
        "\n",
        "There are many different [tensor datatypes available in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEYFi9FoGtRf"
      },
      "source": [
        "Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
        "\n",
        "The most common type (and generally the default) is `torch.float32` or `torch.float`. But there's also 16-bit floating point (`torch.float16` or `torch.half`) and 64-bit floating point (`torch.float64` or `torch.double`). There's also 8-bit, 16-bit, 32-bit and 64-bit integers.\n",
        "\n",
        "**Note:** An integer is a flat round number like `7` whereas a float has a decimal `7.0`.\n",
        "\n",
        "\n",
        "**Resources:**\n",
        "  * See the [PyTorch documentation for a list of all available tensor datatypes](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
        "  * Read the [Wikipedia page for an overview of what is precision in computing](https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
        "\n",
        "Let's see how to create some tensors with specific datatypes. We can do so using the `dtype` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3MoGnpw9XaF",
        "outputId": "a46fc898-b1d2-42a8-b250-01827d831c79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Default datatype for tensors is float32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
        "                               device=None, # defaults to None, which uses the default tensor type\n",
        "                               requires_grad=False) # if True, operations performed on the tensor are recorded\n",
        "\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thOSXLf1mD6u"
      },
      "source": [
        "## **6 Manipulating tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdiWvoAi7UjL"
      },
      "source": [
        "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
        "\n",
        "A model learns by investigating those tensors and performing a series of operations on tensors to create a representation of the patterns in the input data.\n",
        "\n",
        "These operations are often a wonderful dance between:\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk_6Dd7L7Uce"
      },
      "source": [
        "### **6.1 Basic operations**\n",
        "\n",
        "Let's start with a few of the fundamental operations, addition (`+`), subtraction (`-`), mutliplication (`*`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X71WpQoPD7a4",
        "outputId": "1080da76-b761-4d0c-cfac-60f88de125c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor of values and add a number to it\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp4TlTWWEFeO",
        "outputId": "5a7ec001-307b-4008-9670-223ef9ab48c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Multiply it by 10\n",
        "tensor * 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYvqGpUTk1o6"
      },
      "source": [
        "Let's subtract a number and this time we'll reassign the `tensor` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4iWKoLsENry",
        "outputId": "d682efd8-fdc9-46c3-b76d-8d6dd9fa3ced"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Subtract and reassign\n",
        "tensor = tensor - 10\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFgZY-PaFNXa",
        "outputId": "e7587da7-969c-47f4-ed9c-af4db2b9f0c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add and reassign\n",
        "tensor = tensor + 10\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYXDoIOzk-6I"
      },
      "source": [
        "PyTorch also has a bunch of built-in functions like [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) (short for multiplication) and [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html) to perform basic operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVysdk3kFWbY",
        "outputId": "e1bd0325-8ce0-4263-ff13-c346b38c8b19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Can also use torch functions\n",
        "torch.multiply(tensor, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5v3RkR0F2Jq",
        "outputId": "3fa31043-7609-489c-864b-388c46f4e2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n"
          ]
        }
      ],
      "source": [
        "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
        "print(tensor, \"*\", tensor)\n",
        "print(\"Equals:\", tensor * tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT5fVuyu7q5z"
      },
      "source": [
        "### **6.2 Matrix Multiplication: The Foundation of Neural Networks**\n",
        "\n",
        "**Theoretical Significance:**\n",
        "Matrix multiplication represents the most fundamental operation in deep learning. The famous phrase *\"Attention is All You Need\"* from the Transformer paper could equally apply to matrix multiplication in neural networks.\n",
        "\n",
        "#### **6.2.1 Mathematical Definition**\n",
        "\n",
        "For matrices **A** ‚àà ‚Ñù·µêÀ£‚Åø and **B** ‚àà ‚Ñù‚ÅøÀ£·µñ, their product **C** = **AB** ‚àà ‚Ñù·µêÀ£·µñ is defined as:\n",
        "\n",
        "C[i,j] = Œ£‚Çñ‚Çå‚ÇÅ‚Åø A[i,k] √ó B[k,j]\n",
        "\n",
        "#### **6.2.2 Deep Learning Applications**\n",
        "\n",
        "**Neural Network Forward Pass:**\n",
        "- Linear layers: **y** = **Wx** + **b**\n",
        "- Attention mechanisms: **Attention**(**Q**,**K**,**V**) = softmax(**QK**·µÄ/‚àöd)**V**\n",
        "- Convolutional operations: Implemented as matrix multiplications via im2col\n",
        "\n",
        "**Training Process:**\n",
        "- Gradient computation: **‚àÇL/‚àÇW** involves matrix products\n",
        "- Backpropagation: Chain rule applications through matrix operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5JK310vMvWZ"
      },
      "source": [
        "#### **6.2.3 Matrix Multiplication Rules and Implementation**\n",
        "\n",
        "PyTorch implements matrix multiplication through the [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) function, which handles various tensor dimensions automatically.\n",
        "\n",
        "**Critical Rules for Matrix Multiplication:**\n",
        "\n",
        "**Rule 1: Inner Dimension Compatibility**\n",
        "The inner dimensions of the matrices must match for multiplication to be possible:\n",
        "- **Valid**: (m, n) @ (n, p) ‚Üí (m, p) ‚úì\n",
        "- **Invalid**: (m, n) @ (k, p) where n ‚â† k ‚úó\n",
        "\n",
        "**Examples:**\n",
        "- `(3, 2) @ (3, 2)` ‚Üí **Invalid** (inner dimensions: 2 ‚â† 3)\n",
        "- `(2, 3) @ (3, 2)` ‚Üí **Valid** (inner dimensions: 3 = 3) ‚Üí Result: (2, 2)\n",
        "- `(3, 2) @ (2, 3)` ‚Üí **Valid** (inner dimensions: 2 = 2) ‚Üí Result: (3, 3)\n",
        "\n",
        "**Rule 2: Output Shape Determination**\n",
        "The resulting matrix has the shape of the outer dimensions:\n",
        "- (m, **n**) @ (**n**, p) ‚Üí (m, p)\n",
        "- The inner dimensions (**n**) are \"consumed\" during multiplication\n",
        "\n",
        "**Operator Notation:**\n",
        "- **Recommended**: `torch.matmul(A, B)` or `A @ B`\n",
        "- **Alternative**: `torch.mm(A, B)` for 2D matrices only\n",
        "- **Note**: The `@` operator is the standard Python matrix multiplication symbol (PEP 465)\n",
        "\n",
        "**Computational Complexity:**\n",
        "- **Time complexity**: O(mnp) for (m,n) @ (n,p)\n",
        "- **Space complexity**: O(mp) for the result matrix\n",
        "- **GPU acceleration**: Highly optimized on modern GPUs using libraries like cuBLAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE7loucmDlEM",
        "outputId": "c5f9c0ba-b6b0-463f-89dc-a062294ffb21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUAZ3_b0vOKv"
      },
      "source": [
        "The difference between element-wise multiplication and matrix multiplication is the addition of values.\n",
        "\n",
        "For our `tensor` variable with values `[1, 2, 3]`:\n",
        "\n",
        "| Operation | Calculation | Code |\n",
        "| ----- | ----- | ----- |\n",
        "| **Element-wise multiplication** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
        "| **Matrix multiplication** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i42gkUeHvI_1",
        "outputId": "6bcf3a8f-fdad-4268-f4b2-149d57240b6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Element-wise matrix multiplication\n",
        "tensor * tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvCBiiTTDk8y",
        "outputId": "2895108a-0db3-4665-9f2b-6f9e03abf591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector tensor: tensor([1, 2, 3])\n",
            "Vector shape: torch.Size([3])\n",
            "\n",
            "=== MATRIX MULTIPLICATION (DOT PRODUCT) ===\n",
            "Operation: torch.matmul(tensor([1, 2, 3]), tensor([1, 2, 3]))\n",
            "Mathematical computation: (1√ó1) + (2√ó2) + (3√ó3) = 1 + 4 + 9 = 14\n",
            "Result: 14\n",
            "Result shape: torch.Size([])\n",
            "Result type: <class 'int'> value = 14\n",
            "\n",
            "=== MACHINE LEARNING INTERPRETATIONS ===\n",
            "1. Similarity measure: Higher dot product indicates more similar vectors\n",
            "2. Energy/norm calculation: ||v||¬≤ = v¬∑v (when v=tensor)\n",
            "3. Vector magnitude: ||v|| = ‚àö(v¬∑v) = ‚àö14 = 3.7417\n",
            "4. Neural network computation: Linear layer output = input¬∑weights\n",
            "\n",
            "=== COMPUTATIONAL NOTES ===\n",
            "Matrix multiplication is highly optimized in PyTorch:\n",
            "- Uses BLAS (Basic Linear Algebra Subprograms) libraries\n",
            "- Automatically leverages multiple CPU cores\n",
            "- GPU acceleration available via cuBLAS on CUDA devices\n",
            "- Essential operation for neural network forward/backward passes\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Demonstrate matrix multiplication using torch.matmul()\n",
        "# This example shows the mathematical difference between element-wise and matrix multiplication\n",
        "\n",
        "# Using the previously defined tensor: [1, 2, 3]\n",
        "print(f\"Vector tensor: {tensor}\")\n",
        "print(f\"Vector shape: {tensor.shape}\")\n",
        "\n",
        "# Matrix multiplication for vectors computes the dot product\n",
        "# Mathematical formula: v ¬∑ v = Œ£·µ¢ v·µ¢ √ó v·µ¢ = v‚ÇÅ¬≤ + v‚ÇÇ¬≤ + v‚ÇÉ¬≤\n",
        "matrix_result = torch.matmul(tensor, tensor)\n",
        "\n",
        "print(f\"\\n=== MATRIX MULTIPLICATION (DOT PRODUCT) ===\")\n",
        "print(f\"Operation: torch.matmul({tensor}, {tensor})\")\n",
        "print(f\"Mathematical computation: (1√ó1) + (2√ó2) + (3√ó3) = 1 + 4 + 9 = 14\")\n",
        "print(f\"Result: {matrix_result}\")\n",
        "print(f\"Result shape: {matrix_result.shape}\")  # Scalar result (0-dimensional)\n",
        "print(f\"Result type: {type(matrix_result.item())} value = {matrix_result.item()}\")\n",
        "\n",
        "# Interpretation in machine learning contexts:\n",
        "print(f\"\\n=== MACHINE LEARNING INTERPRETATIONS ===\")\n",
        "print(\"1. Similarity measure: Higher dot product indicates more similar vectors\")\n",
        "print(\"2. Energy/norm calculation: ||v||¬≤ = v¬∑v (when v=tensor)\")\n",
        "print(f\"3. Vector magnitude: ||v|| = ‚àö(v¬∑v) = ‚àö{matrix_result.item()} = {torch.sqrt(matrix_result).item():.4f}\")\n",
        "print(\"4. Neural network computation: Linear layer output = input¬∑weights\")\n",
        "\n",
        "# Computational efficiency note:\n",
        "print(f\"\\n=== COMPUTATIONAL NOTES ===\")\n",
        "print(\"Matrix multiplication is highly optimized in PyTorch:\")\n",
        "print(\"- Uses BLAS (Basic Linear Algebra Subprograms) libraries\")\n",
        "print(\"- Automatically leverages multiple CPU cores\")\n",
        "print(\"- GPU acceleration available via cuBLAS on CUDA devices\")\n",
        "print(\"- Essential operation for neural network forward/backward passes\")\n",
        "\n",
        "matrix_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4E_pROBDk2r",
        "outputId": "275f0107-0716-4a7f-a199-fd4083439821"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Can also use the \"@\" symbol for matrix multiplication, though not recommended\n",
        "tensor @ tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjMmrJOOPv5e"
      },
      "source": [
        "### **6.3 Aggregation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrFQbe5fP1Rk",
        "outputId": "bd97452f-bc5e-4399-aa09-25c10837cc42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5wSP9YKP3Lb",
        "outputId": "28752228-2fa6-4c4f-81fc-2f04dca6fe94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Sum: 450\n"
          ]
        }
      ],
      "source": [
        "print(f\"Minimum: {x.min()}\")\n",
        "print(f\"Maximum: {x.max()}\")\n",
        "print(f\"Sum: {x.sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gjVEiRRmD6y",
        "outputId": "e8cea997-8607-4b16-87a9-817adc6abd9e"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# this will give error\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
          ]
        }
      ],
      "source": [
        "print(f\"Mean: {x.mean()}\") # this will give error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnmFuNK0mD6y",
        "outputId": "1e45f030-feab-464e-a0b2-56a3f65b47ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean: 45.0\n"
          ]
        }
      ],
      "source": [
        "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHoKpsg3sKQE"
      },
      "source": [
        "> **Note:** You may find some methods such as `torch.mean()` require tensors to be in `torch.float32` (the most common) or another specific datatype, otherwise the operation will fail.\n",
        "\n",
        "You can also do the same as above with `torch` methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cr23Y9uP3HO",
        "outputId": "e1d45afe-7c43-4818-a45f-32bd4f0a7e38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(90), tensor(0), tensor(45.), tensor(450))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7ApCaZjDkvp"
      },
      "source": [
        "### **6.4 Positional min/max**\n",
        "\n",
        "You can also find the index of a tensor where the max or minimum occurs with [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) and [`torch.argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html) respectively.\n",
        "\n",
        "This is helpful incase you just want the position where the highest (or lowest) value is and not the actual value itself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzNBl9JSGlHi",
        "outputId": "d2d0fab5-1121-4379-f63e-0d82d3a26188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Index where max value occurs: 8\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"Tensor: {tensor}\")\n",
        "\n",
        "# Returns index of max and min values\n",
        "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
        "print(f\"Index where min value occurs: {tensor.argmin()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CkCtAYmGsHY"
      },
      "source": [
        "### **6.5 Reshaping, Stacking, Squeezing and Unsqueezing**\n",
        "\n",
        "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmQfLKCxK6SQ"
      },
      "source": [
        "\n",
        "| Method | One-line description |\n",
        "| ----- | ----- |\n",
        "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Reshapes `input` to `shape` (if compatible), can also use `torch.Tensor.reshape()`. |\n",
        "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Returns a view of the original tensor in a different `shape` but shares the same data as the original tensor. |\n",
        "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatenates a sequence of `tensors` along a new dimension (`dim`), all `tensors` must be same size. |\n",
        "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Squeezes `input` to remove all the dimenions with value `1`. |\n",
        "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Returns `input` with a dimension value of `1` added at `dim`. |\n",
        "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Returns a *view* of the original `input` with its dimensions permuted (rearranged) to `dims`. |\n",
        "\n",
        "Why do any of these?\n",
        "\n",
        "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYjRTLOzG4Ev",
        "outputId": "56b18f61-86c5-44e6-a708-ad3c5153a75e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 8.)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_VarMO9CoT8"
      },
      "source": [
        "Now let's add an extra dimension with `torch.reshape()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US4WjpQ3SG-8",
        "outputId": "4f603adb-07f9-4a29-a999-aa46f84a6a59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(1, 7)\n",
        "x_reshaped, x_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDN2BNe5TGfB",
        "outputId": "3b3d4704-e5b6-4da6-d7fd-819d696d0563"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change view (keeps same data as original but changes view)\n",
        "# See more: https://stackoverflow.com/a/54507446/7900723\n",
        "z = x.view(1, 7)\n",
        "z, z.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8joAaUEC2NX"
      },
      "source": [
        "Remember though, changing the view of a tensor with `torch.view()` really only creates a new view of the *same* tensor.\n",
        "\n",
        "So changing the view changes the original tensor too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DxURVvXTGfC",
        "outputId": "e02451d7-021b-4639-b6b6-bd5dc3918dbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Changing z changes x\n",
        "z[:, 0] = 5\n",
        "z, x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxnqDBlpDDJ_"
      },
      "source": [
        "If we wanted to stack our new tensor on top of itself five times, we could do so with `torch.stack()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX5Adf3ORiTK",
        "outputId": "dbb2804c-168a-414f-953e-5ce8533c7a63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
        "x_stacked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET56QzNHDuOI"
      },
      "source": [
        "How about removing all single dimensions from a tensor?\n",
        "\n",
        "To do so you can use `torch.squeeze()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2Y2HEoDRxJZ",
        "outputId": "d9d652a0-88d7-4760-a753-0d54b5bf315e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
            "Previous shape: torch.Size([1, 7])\n",
            "\n",
            "New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "New shape: torch.Size([7])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimension from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acjDLk8WD8NC"
      },
      "source": [
        "And to do the reverse of `torch.squeeze()` you can use `torch.unsqueeze()` to add a dimension value of 1 at a specific index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUC-DEEwSYv7",
        "outputId": "3291344e-bd3f-4e91-e2a7-b0fcb3116750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "Previous shape: torch.Size([7])\n",
            "\n",
            "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
            "New shape: torch.Size([1, 7])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Previous tensor: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "## Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9DuJzXgFbM5"
      },
      "source": [
        "You can also rearrange the order of axes values with `torch.permute(input, dims)`, where the `input` gets turned into a *view* with new `dims`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCRGCX8DTGfC",
        "outputId": "f5a49d3d-e75c-438b-8fcb-84aa412256f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# Create tensor with specific shape\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# Permute the original tensor to rearrange the axis order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06LKaFemGBoE"
      },
      "source": [
        "> **Note**: Because permuting returns a *view* (shares the same data as the original), the values in the permuted tensor will be the same as the original tensor and if you change the values in the view, it will change the values of the original."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEPqVL7fTGfC"
      },
      "source": [
        "### **6.6 Indexing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSXzdxCQTGfD",
        "outputId": "46a79b23-8d66-44f6-bc98-9ed53889973f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQG5krnKG43B"
      },
      "source": [
        "Indexing values goes outer dimension -> inner dimension (check out the square brackets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv_Z3IAzTGfD",
        "outputId": "d0b01fd4-c0ce-496a-80ed-13903a1fd70a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First square bracket:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Second square bracket: tensor([1, 2, 3])\n",
            "Third square bracket: 1\n"
          ]
        }
      ],
      "source": [
        "# Let's index bracket by bracket\n",
        "print(f\"First square bracket:\\n{x[0]}\")\n",
        "print(f\"Second square bracket: {x[0][0]}\")\n",
        "print(f\"Third square bracket: {x[0][0][0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaLjaIFxHe89"
      },
      "source": [
        "You can also use `:` to specify \"all values in this dimension\" and then use a comma (`,`) to add another dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCT09pqeTGfD",
        "outputId": "f9528172-7afa-4cb1-8fcb-6bfb2b683739"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
        "x[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwDx_gMsTGfD",
        "outputId": "9fdb0782-7fcd-479f-d11e-8bcfc5bcbab2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
        "x[:, :, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiw3_1E3TGfD",
        "outputId": "3f3caff0-1587-4da8-8fff-5fce80e10817"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
        "x[:, 1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFVEgrKhTGfD",
        "outputId": "ee746326-3ccb-43ce-ccd4-227e8cc47a1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "x[0, 0, :] # same as x[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfJBmLY0mD61"
      },
      "source": [
        "## **7 PyTorch tensors & NumPy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8ZaW0Bq7rCm"
      },
      "source": [
        "PyTorch has functionality to interact with numpy.  \n",
        "\n",
        "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
        "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - NumPy array -> PyTorch tensor.\n",
        "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - PyTorch tensor -> NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDrDCnvY7rKS",
        "outputId": "bf7ed173-98f2-4e7d-dcd3-0ed79fa7f632"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NumPy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16JG6cONLPnO"
      },
      "source": [
        "> **Note:** By default, NumPy arrays are created with the datatype `float64` and if you convert it to a PyTorch tensor, it'll keep the same datatype (as above).\n",
        ">\n",
        "> However, many PyTorch calculations default to using `float32`.\n",
        ">\n",
        "> So if you want to convert your NumPy array (float64) -> PyTorch tensor (float64) -> PyTorch tensor (float32), you can use `tensor = torch.from_numpy(array).type(torch.float32)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw_7ZyVaTKxQ",
        "outputId": "733c1570-7601-4b5f-9e83-2ecf0b018340"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
        "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gU3ubCrUkI-"
      },
      "source": [
        "## **8 Reproducibility**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everytime the below code block runs, random_tensor_A gets a new value."
      ],
      "metadata": {
        "id": "0bZUD01gL6Wj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSwxnwEbTGfF",
        "outputId": "4dc7a51a-f03a-4b54-8a31-500c0eefb74c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A:\n",
            "tensor([[0.7539, 0.1952, 0.0050, 0.3068],\n",
            "        [0.1165, 0.9103, 0.6440, 0.7071],\n",
            "        [0.6581, 0.4913, 0.8913, 0.1447]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create two random tensors\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor A:\\n{random_tensor_A}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB6d1GfYTGfF",
        "outputId": "c0bc165b-1d6e-4414-ab2e-f01f35d006ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Set the random seed\n",
        "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
        "\n",
        "# Feed the random seed to PyTorch\n",
        "torch.manual_seed(seed=RANDOM_SEED)\n",
        "\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "print(f\"Tensor A:\\n{random_tensor_A}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c43476a-c975-42e9-c69e-2652e64a7e8c",
        "id": "g8I2yJKEMXn5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A:\n",
            "tensor([[0.6130, 0.0101, 0.3984, 0.0403],\n",
            "        [0.1563, 0.4825, 0.7362, 0.4060],\n",
            "        [0.5189, 0.2867, 0.2416, 0.9228]], device='cuda:0')\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Set the random seed\n",
        "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
        "\n",
        "# Feed the random seed to GPU\n",
        "torch.cuda.manual_seed(seed=RANDOM_SEED)\n",
        "\n",
        "random_tensor_A = torch.rand(3, 4, device='cuda')\n",
        "print(f\"Tensor A:\\n{random_tensor_A}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB9rhCdMmD64"
      },
      "source": [
        "## **9 GPU Acceleration for High-Performance Computing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxIIM7t27rQ-"
      },
      "source": [
        "### **9.1 Theoretical Foundation**\n",
        "\n",
        "**Graphics Processing Units (GPUs)** have revolutionized deep learning by providing massively parallel computational capabilities. Understanding GPU utilization is essential for practical deep learning applications.\n",
        "\n",
        "#### **9.1.1 CPU vs GPU Architecture**\n",
        "\n",
        "**Central Processing Unit (CPU):**\n",
        "- **Design philosophy**: Optimized for sequential processing and complex control logic\n",
        "- **Core count**: Typically 4-32 cores with sophisticated caching\n",
        "- **Memory**: Large, hierarchical cache systems\n",
        "- **Best for**: Complex branching, single-threaded performance, system management\n",
        "\n",
        "**Graphics Processing Unit (GPU):**\n",
        "- **Design philosophy**: Optimized for parallel processing of simple operations\n",
        "- **Core count**: Thousands of simple cores (e.g., 2,048-10,496 CUDA cores)\n",
        "- **Memory**: High-bandwidth memory (HBM) with lower latency tolerance\n",
        "- **Best for**: Matrix operations, element-wise computations, data parallelism\n",
        "\n",
        "#### **9.1.2 CUDA Ecosystem**\n",
        "\n",
        "**CUDA (Compute Unified Device Architecture)** enables general-purpose computing on NVIDIA GPUs:\n",
        "- **Programming model**: Parallel computing platform and API\n",
        "- **Memory hierarchy**: Global, shared, constant, and texture memory types\n",
        "- **Execution model**: Kernel launches with thread blocks and grids\n",
        "- **Library ecosystem**: cuBLAS, cuDNN, cuSPARSE for optimized operations\n",
        "\n",
        "**Note:** This tutorial focuses on NVIDIA GPUs with CUDA support. Alternative platforms include AMD ROCm and Intel oneAPI, but CUDA remains the most widely supported in deep learning frameworks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UiR6QpoYQH_"
      },
      "source": [
        "### **9.2 Getting a GPU**\n",
        "\n",
        "To check if you've got access to a Nvidia GPU, you can run `!nvidia-smi` where the `!` (also called bang) means \"run this on the command line\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEMcO-9zYc-w",
        "outputId": "79f3b45c-b9c4-45db-e397-87cbafeb4f9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Aug 21 17:54:19 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Quadro K2200                   Off | 00000000:01:00.0  On |                  N/A |\n",
            "| 43%   46C    P8               1W /  39W |    423MiB /  4096MiB |     21%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA GeForce RTX 3090        Off | 00000000:04:00.0 Off |                  N/A |\n",
            "| 30%   37C    P8              25W / 350W |    358MiB / 24576MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A      1297      G   /usr/lib/xorg/Xorg                           31MiB |\n",
            "|    0   N/A  N/A      1680      G   /usr/lib/xorg/Xorg                          153MiB |\n",
            "|    0   N/A  N/A      1805      G   /usr/bin/gnome-shell                         46MiB |\n",
            "|    0   N/A  N/A      2367      G   /usr/lib/firefox/firefox                     15MiB |\n",
            "|    0   N/A  N/A      6055      G   /proc/self/exe                              159MiB |\n",
            "|    1   N/A  N/A      1297      G   /usr/lib/xorg/Xorg                            4MiB |\n",
            "|    1   N/A  N/A      1680      G   /usr/lib/xorg/Xorg                            4MiB |\n",
            "|    1   N/A  N/A   2822198      C   ...a/mirl/DATA/Projects/env/bin/python      336MiB |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvkB9p5zYf8E"
      },
      "source": [
        "If you don't have a Nvidia GPU accessible, the above will output something like:\n",
        "\n",
        "```\n",
        "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
        "```\n",
        "\n",
        "If you do have a GPU, the line above will output something like:\n",
        "\n",
        "```\n",
        "Wed Jan 19 22:09:08 2022       \n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
        "|                               |                      |                  N/A |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "                                                                               \n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                                  |\n",
        "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "|        ID   ID                                                   Usage      |\n",
        "|=============================================================================|\n",
        "|  No running processes found                                                 |\n",
        "+-----------------------------------------------------------------------------+\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvibZ6e0YcDk"
      },
      "source": [
        "### **9.3 Getting PyTorch to run on the GPU**\n",
        "\n",
        "You can test if PyTorch has access to a GPU using [`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OweDLgwjEvZ2",
        "outputId": "5aa23685-4cd4-4b87-a71c-b5e2f5e66bde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== GPU AVAILABILITY DIAGNOSTIC ===\n",
            "CUDA Available: True\n",
            "\n",
            "=== GPU HARDWARE DETAILS ===\n",
            "Number of GPUs: 2\n",
            "Current GPU Device: 0\n",
            "GPU Name: NVIDIA GeForce RTX 3090\n",
            "\n",
            "=== MEMORY CONFIGURATION ===\n",
            "Total GPU Memory: 23.69 GB\n",
            "Currently Allocated: 0.00 MB\n",
            "Currently Reserved: 0.00 MB\n",
            "Available Memory: 23.69 GB\n",
            "\n",
            "=== SOFTWARE VERSIONS ===\n",
            "PyTorch Version: 2.4.1+cu121\n",
            "CUDA Version: 12.1\n",
            "cuDNN Version: 90100\n",
            "cuDNN Enabled: True\n",
            "\n",
            "=== PERFORMANCE EXPECTATIONS ===\n",
            "‚úì GPU acceleration available - expect 10-100x speedup for large models\n",
            "‚úì Large batch sizes supported (limited by GPU memory)\n",
            "‚úì Suitable for production-scale training\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check CUDA availability and system configuration\n",
        "# This diagnostic is crucial for ensuring optimal performance in deep learning workflows\n",
        "\n",
        "import torch\n",
        "\n",
        "# Primary CUDA availability check\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "print(\"=== GPU AVAILABILITY DIAGNOSTIC ===\")\n",
        "print(f\"CUDA Available: {cuda_available}\")\n",
        "\n",
        "if cuda_available:\n",
        "    # Detailed GPU information for performance optimization\n",
        "    print(f\"\\n=== GPU HARDWARE DETAILS ===\")\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "    print(f\"Current GPU Device: {torch.cuda.current_device()}\")\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "    # Memory analysis - critical for batch size optimization\n",
        "    print(f\"\\n=== MEMORY CONFIGURATION ===\")\n",
        "    memory_allocated = torch.cuda.memory_allocated(0)\n",
        "    memory_reserved = torch.cuda.memory_reserved(0)\n",
        "    total_memory = torch.cuda.get_device_properties(0).total_memory\n",
        "\n",
        "    print(f\"Total GPU Memory: {total_memory / 1024**3:.2f} GB\")\n",
        "    print(f\"Currently Allocated: {memory_allocated / 1024**2:.2f} MB\")\n",
        "    print(f\"Currently Reserved: {memory_reserved / 1024**2:.2f} MB\")\n",
        "    print(f\"Available Memory: {(total_memory - memory_reserved) / 1024**3:.2f} GB\")\n",
        "\n",
        "    # CUDA version compatibility\n",
        "    print(f\"\\n=== SOFTWARE VERSIONS ===\")\n",
        "    print(f\"PyTorch Version: {torch.__version__}\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"cuDNN Version: {torch.backends.cudnn.version()}\")\n",
        "    print(f\"cuDNN Enabled: {torch.backends.cudnn.enabled}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n=== CPU-ONLY CONFIGURATION ===\")\n",
        "    print(\"GPU acceleration not available. Training will use CPU.\")\n",
        "    print(\"For large models, consider:\")\n",
        "    print(\"1. Cloud services (Google Colab, AWS, Azure)\")\n",
        "    print(\"2. CUDA-compatible GPU installation\")\n",
        "    print(\"3. Reduced model size and batch size for CPU training\")\n",
        "\n",
        "# Performance implications:\n",
        "print(f\"\\n=== PERFORMANCE EXPECTATIONS ===\")\n",
        "if cuda_available:\n",
        "    print(\"‚úì GPU acceleration available - expect 10-100x speedup for large models\")\n",
        "    print(\"‚úì Large batch sizes supported (limited by GPU memory)\")\n",
        "    print(\"‚úì Suitable for production-scale training\")\n",
        "else:\n",
        "    print(\"‚ö† CPU-only mode - expect slower training\")\n",
        "    print(\"‚ö† Smaller batch sizes recommended\")\n",
        "    print(\"‚ö† Consider GPU resources for larger experiments\")\n",
        "\n",
        "cuda_available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j92HBCKB7rYa",
        "outputId": "24f86977-b148-43c2-f682-66edeea884d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set device type\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjFyPP2WaCch"
      },
      "source": [
        "If the above output `\"cuda\"` it means we can set all of our PyTorch code to use the available CUDA device (a GPU) and if the output is `\"cpu\"`, our PyTorch code will stick with the CPU.\n",
        "\n",
        "> **Note:** In PyTorch, it's best practice to write [**device agnostic code**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code). This means that the code will run on CPU (always available) or GPU (if available)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MArsn0DFTGfG",
        "outputId": "fbef893c-a17a-43a4-ff64-2b8a3b256e26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqQLcuj68OA-"
      },
      "source": [
        "### **9.4 Putting tensors (and models) on the GPU**\n",
        "\n",
        "You can put tensors (and models, we'll see this later) on a specific device by calling [`to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) on them. Where `device` is the target device you'd like the tensor (or model) to go to.\n",
        "\n",
        "Why do this?\n",
        "\n",
        "GPUs offer far faster numerical computing than CPUs do and if a GPU isn't available, because of our **device agnostic code** (see above), it'll run on the CPU.\n",
        "\n",
        "> **Note:** Putting a tensor on GPU using `to(device)` (e.g. `some_tensor.to(device)`) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. To overwrite tensors, reassign them:\n",
        ">\n",
        "> `some_tensor = some_tensor.to(device)`\n",
        "\n",
        "Let's try creating a tensor and putting it on the GPU (if it's available)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhI3srFXEHfP",
        "outputId": "1fc601bc-d220-4e2b-d514-1a03298b3246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create tensor (default on CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxXeRKO0TGfG"
      },
      "source": [
        "If you have a GPU available, the above code will output something like:\n",
        "\n",
        "```\n",
        "tensor([1, 2, 3]) cpu\n",
        "tensor([1, 2, 3], device='cuda:0')\n",
        "```\n",
        "\n",
        "Notice the second tensor has `device='cuda:0'`, this means it's stored on the 0th GPU available (GPUs are 0 indexed, if two GPUs were available, they'd be `'cuda:0'` and `'cuda:1'` respectively, up to `'cuda:n'`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4puyUX4Bci5D"
      },
      "source": [
        "### **9.5 Moving tensors back to the CPU**\n",
        "\n",
        "What if we wanted to move the tensor back to CPU?\n",
        "\n",
        "For example, you'll want to do this if you want to interact with your tensors with NumPy (NumPy does not leverage the GPU).\n",
        "\n",
        "Let's try using the [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) method on our `tensor_on_gpu`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "3ChSLJgPTGfG",
        "outputId": "cc700f01-00be-4c72-dbe0-c533a7002d35"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# If tensor is on GPU, can't transform it to NumPy (this will error)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ],
      "source": [
        "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
        "tensor_on_gpu.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhymtkRDTGfG"
      },
      "source": [
        "Instead, to get a tensor back to CPU and usable with NumPy we can use [`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN15s-NdTGfG",
        "outputId": "f9cff3a3-325a-4388-b8b2-ad3fb5dfdd51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Instead, copy the tensor back to cpu\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyzNH5lrTGfH"
      },
      "source": [
        "The above returns a copy of the GPU tensor in CPU memory so the original tensor is still on GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5u83PCRTGfH",
        "outputId": "3bf46a44-5d8d-4f4f-9183-7aa6e7f0aafe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRnU_zTbSJ7E",
        "outputId": "d5defd58-585c-448d-8b9b-8facbb4396b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_on_gpu.to('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDzQ2j_0mD67"
      },
      "source": [
        "## **10 Most Common Errors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ4DDmo1TGe-"
      },
      "source": [
        "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNFXctq-J1eR"
      },
      "source": [
        "### **10.1 Tensor shape**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "rN5RcoD4Jo6y",
        "outputId": "579bd20e-da2e-4543-fad2-7d75f059ede4"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[59], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m      3\u001b[0m                          [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],\n\u001b[1;32m      4\u001b[0m                          [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m],\n\u001b[1;32m      8\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (this will error)\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ],
      "source": [
        "# Shapes need to be in the right way\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "torch.matmul(tensor_A, tensor_B) # (this will error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUqgaANiy1wq",
        "outputId": "fb4ce0ed-cfa1-49d1-bace-74604a920f16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7., 10.],\n",
            "        [ 8., 11.],\n",
            "        [ 9., 12.]])\n"
          ]
        }
      ],
      "source": [
        "# View tensor_A and tensor_B\n",
        "print(tensor_A)\n",
        "print(tensor_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DveqxO7iy_Fi",
        "outputId": "e9a6812e-c310-489a-ed78-9f0f4d1e2abe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n"
          ]
        }
      ],
      "source": [
        "# View tensor_A and tensor_B.T\n",
        "print(tensor_A)\n",
        "print(tensor_B.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35rEIu-NKtVE",
        "outputId": "b30c1975-3204-4d31-b018-062861672ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# The operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3rJvW_TTGe_",
        "outputId": "4549819e-d6a6-48f0-c3e4-3656ad05294d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# torch.mm is a shortcut for matmul\n",
        "torch.mm(tensor_A, tensor_B.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBu33WihOXBk"
      },
      "source": [
        "### **10.2 Tensor datatype**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DllO9DA7NK2T"
      },
      "source": [
        "As mentioned, a common issue with deep learning operations is having your tensors in different datatypes.\n",
        "\n",
        "If one tensor is in `torch.float64` and another is in `torch.float32`, you might run into some errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "0N2-cyruNLo4",
        "outputId": "2753f3cd-2d3c-4470-8870-831939f11c19"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "dot : expected both vectors to have same dtype, but found Half and Float",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[64], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m tensor1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m10.\u001b[39m, \u001b[38;5;241m100.\u001b[39m, \u001b[38;5;241m10.\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[1;32m      2\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m10.\u001b[39m, \u001b[38;5;241m100.\u001b[39m, \u001b[38;5;241m10.\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtensor1\u001b[49m\u001b[38;5;129;43m@tensor2\u001b[39;49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: dot : expected both vectors to have same dtype, but found Half and Float"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.arange(10., 100., 10., dtype=torch.float16)\n",
        "tensor2 = torch.arange(10., 100., 10.)\n",
        "\n",
        "tensor1@tensor2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KN2huCJMGVo"
      },
      "source": [
        "You can change the datatypes of tensors using [`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html) where the `dtype` parameter is the datatype you'd like to use.\n",
        "\n",
        "First we'll create a tensor and check its datatype (the default is `torch.float32`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY2FEsCAOaLu",
        "outputId": "7ba612b7-abc8-425b-8b29-4e0ba04f5c34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor and check its datatype\n",
        "tensor = torch.arange(10., 100., 10.)\n",
        "tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR30FHEc92of"
      },
      "source": [
        "Now we'll create another tensor the same as before but change its datatype to `torch.float16`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cac8gRYjOeab",
        "outputId": "2f1cc401-1243-41ac-91a5-720a00659e6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a float16 tensor\n",
        "tensor_float16 = tensor.type(torch.float16)\n",
        "tensor_float16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndVlKJZ4-7_5"
      },
      "source": [
        "And we can do something similar to make a `torch.int8` tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U4MZvzVSlwH",
        "outputId": "543d8907-13ba-42a6-cfce-9363a60053a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(28496., dtype=torch.float16)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor1@tensor2.type(torch.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1G3qtD4Sx5Q",
        "outputId": "a847c5a8-3ed6-44c5-b98e-436a6fd82204"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(28500.)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor1.type(torch.float32)@tensor2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yqovld2Oj6s",
        "outputId": "4fad6773-f824-4f77-d50f-ebca0e118e18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create an int8 tensor\n",
        "tensor_int8 = tensor.type(torch.int8)\n",
        "tensor_int8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my_PxWOVNvNg"
      },
      "source": [
        "### **10.3 Tensor device**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "ugX_H-vsNv4w",
        "outputId": "7f86e902-35bd-46a9-c631-4d6304bb34ec"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensor in method wrapper_CUDA__dot)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[70], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m tensor1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m10.\u001b[39m, \u001b[38;5;241m100.\u001b[39m, \u001b[38;5;241m10.\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m10.\u001b[39m, \u001b[38;5;241m100.\u001b[39m, \u001b[38;5;241m10.\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtensor1\u001b[49m\u001b[38;5;129;43m@tensor2\u001b[39;49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensor in method wrapper_CUDA__dot)"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.arange(10., 100., 10., device='cpu')\n",
        "tensor2 = torch.arange(10., 100., 10., device='cuda')\n",
        "\n",
        "tensor1@tensor2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR2j2yONSZVt",
        "outputId": "f62b0bd5-937d-4f12-c9d9-45e5488862fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(28500., device='cuda:0')"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor1.to('cuda')@tensor2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF9gul-nmD6-"
      },
      "source": [
        "## **11. Summary and Debugging Guidelines**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYbtqfhhmD6-"
      },
      "source": [
        "### **11.1 Common Error Categories in PyTorch**\n",
        "\n",
        "When developing deep learning applications, most errors fall into three primary categories. Remember this diagnostic song for systematic debugging:\n",
        "\n",
        "> **\"What, What, Where\"** - *A PyTorch Debugging Mantra*\n",
        ">\n",
        "> *\"What shape are my tensors, what datatype are they, and where are they stored?*\n",
        "> *What shape, what datatype, what what where!\"*\n",
        "\n",
        "#### **11.1.1 Shape Mismatches**\n",
        "- **Symptom**: RuntimeError involving tensor dimensions\n",
        "- **Common causes**: Incompatible matrix multiplication dimensions, CNN input/output mismatches\n",
        "- **Solution strategy**: Print tensor shapes before operations, use `tensor.view()` or `tensor.reshape()`\n",
        "\n",
        "#### **11.1.2 Datatype Incompatibilities**\n",
        "- **Symptom**: Operations between different precision tensors (e.g., float32 vs float64)\n",
        "- **Common causes**: Mixed precision in model parameters and data\n",
        "- **Solution strategy**: Use `tensor.type(torch.float32)` for consistent datatypes\n",
        "\n",
        "#### **11.1.3 Device Mismatches**\n",
        "- **Symptom**: Attempting operations between CPU and GPU tensors\n",
        "- **Common causes**: Forgetting to move tensors to the same device\n",
        "- **Solution strategy**: Implement device-agnostic code with `tensor.to(device)`\n",
        "\n",
        "### **11.2 Best Practices for Production Code**\n",
        "\n",
        "1. **Device Agnostic Development**: Always write code that works on both CPU and GPU\n",
        "2. **Memory Management**: Monitor GPU memory usage and implement proper cleanup\n",
        "3. **Reproducibility**: Set random seeds for consistent experimental results\n",
        "4. **Error Handling**: Implement robust error checking for tensor operations"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}